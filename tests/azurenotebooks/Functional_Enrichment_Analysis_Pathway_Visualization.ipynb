{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToppGene & Pathway Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors: N. Mouchamel, L. Huang, T. Nguyen, K. Fisch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email: Kfisch@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date: June 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Create Jupyter notebook that runs an enrichment analysis in ToppGene through the API and runs Pathview to visualize the significant pathways outputted by ToppGene.\n",
    "\n",
    "\n",
    "toppgene website: https://toppgene.cchmc.org/enrichment.jsp\n",
    "\n",
    "Steps: \n",
    "1. Read in differentially expressed gene list.\n",
    "2. Convert differentially expressed gene list to xml file as input to ToppGene API.\n",
    "3. Run enrichment analysis of DE genes through ToppGene API.\n",
    "4. Parse ToppGene API results from xml to csv and Pandas data frame.\n",
    "5. Display results in notebook.\n",
    "6. Extract just the KEGG pathwway IDs from the ToppGene output.\n",
    "7. Manually switch from Python2 to R kernel.\n",
    "8. Extract entrez ID and  log2FC from the input DE genes.\n",
    "9. Create vector of significant pathways from ToppGene.\n",
    "10. Run Pathview (https://bioconductor.org/packages/release/bioc/html/pathview.html) in R to create colored pathway maps.\n",
    "11. Manually switch from R kernel to Python2.\n",
    "12. Display each of the significant pathway colored overlay diagrams in the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named qgrid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-602679791e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmygene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named qgrid"
     ]
    }
   ],
   "source": [
    "#Import Python modules\n",
    "import os\n",
    "import pandas\n",
    "import qgrid\n",
    "import mygene\n",
    "\n",
    "#Change directory\n",
    "os.chdir(\"/data/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qgrid\n",
      "  Downloading qgrid-1.0.2.tar.gz (757kB)\n",
      "\u001b[K    100% |████████████████████████████████| 757kB 377kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: notebook>=4.0.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from qgrid)\n",
      "Requirement already satisfied: pandas>=0.18.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from qgrid)\n",
      "Collecting ipywidgets>=7.0.0 (from qgrid)\n",
      "  Using cached ipywidgets-7.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from pandas>=0.18.0->qgrid)\n",
      "Requirement already satisfied: pytz>=2011k in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from pandas>=0.18.0->qgrid)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from pandas>=0.18.0->qgrid)\n",
      "Requirement already satisfied: ipython<6.0.0,>=4.0.0; python_version < \"3.3\" in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipywidgets>=7.0.0->qgrid)\n",
      "Collecting widgetsnbextension~=3.1.0 (from ipywidgets>=7.0.0->qgrid)\n",
      "  Using cached widgetsnbextension-3.1.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: six>=1.5 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from python-dateutil->pandas>=0.18.0->qgrid)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: decorator in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: pickleshare in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.4 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: pygments in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: pexpect in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: backports.shutil_get_terminal_size in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: pathlib2 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: ipython_genutils in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: jupyter_core in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: jupyter_client in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: tornado>=4.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: enum34 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: wcwidth in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from prompt_toolkit<2.0.0,>=1.0.4->ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: scandir in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from pathlib2->ipython<6.0.0,>=4.0.0; python_version < \"3.3\"->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: functools32 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from jupyter_client->ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid)\n",
      "Building wheels for collected packages: qgrid\n",
      "  Running setup.py bdist_wheel for qgrid ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/5e/53/11/9161264b35725dce68013a6be4d2ff0bad3df0008755989d7c\n",
      "Successfully built qgrid\n",
      "Installing collected packages: widgetsnbextension, ipywidgets, qgrid\n",
      "  Found existing installation: widgetsnbextension 3.0.0\n",
      "    Uninstalling widgetsnbextension-3.0.0:\n",
      "      Successfully uninstalled widgetsnbextension-3.0.0\n",
      "  Found existing installation: ipywidgets 7.0.0b7\n",
      "    Uninstalling ipywidgets-7.0.0b7:\n",
      "      Successfully uninstalled ipywidgets-7.0.0b7\n",
      "Successfully installed ipywidgets-7.1.2 qgrid-1.0.2 widgetsnbextension-3.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install qgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in differential expression results as a Pandas data frame to get differentially expressed gene list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in DESeq2 results\n",
    "genes=pandas.read_csv(\"DE_genes.csv\")\n",
    "\n",
    "#View top of file\n",
    "genes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract genes that are differentially expressed with a pvalue less than a certain cutoff (pvalue < 0.05 or padj < 0.05)\n",
    "genes_DE_only = genes.loc[(genes.pvalue < 0.05)]\n",
    "\n",
    "#View top of file\n",
    "genes_DE_only.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many rows in original genes file\n",
    "len(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many rows in DE genes file\n",
    "len(genes_DE_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Ensembl IDs to Gene Symbols and Entrez IDs using mygene.info API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract list of DE genes  (Check to make sure this code works, this was adapted from a different notebook)\n",
    "de_list = genes_DE_only[genes_DE_only.columns[0]]\n",
    "\n",
    "#Remove .* from end of Ensembl ID\n",
    "de_list2 = de_list.replace(\"\\.\\d\",\"\",regex=True)\n",
    "\n",
    "#Add new column with reformatted Ensembl IDs\n",
    "genes_DE_only[\"Full_Ensembl\"] = de_list2\n",
    "\n",
    "#View top of file \n",
    "genes_DE_only.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set up mygene.info API and query\n",
    "mg = mygene.MyGeneInfo()\n",
    "gene_ids = mg.getgenes(de_list2, 'name, symbol, entrezgene', as_dataframe=True)\n",
    "gene_ids.index.name = \"Ensembl\"\n",
    "gene_ids.reset_index(inplace=True)\n",
    "\n",
    "#View top of file\n",
    "gene_ids.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge mygene.info query results with original DE genes list\n",
    "DE_with_ids = genes_DE_only.merge(gene_ids, left_on=\"Full_Ensembl\", right_on=\"Ensembl\", how=\"outer\")\n",
    "\n",
    "#View top of file\n",
    "DE_with_ids.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write results to file\n",
    "DE_with_ids.to_csv(\"./DE_genes_converted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dataframe to only contain gene symbol\n",
    "DE_with_ids=pandas.read_csv(\"./DE_genes_converted.csv\")\n",
    "\n",
    "cols = DE_with_ids.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('symbol')))\n",
    "\n",
    "for_xmlfile = DE_with_ids.reindex(columns= cols)\n",
    "\n",
    "#Condense dataframe to contain only gene symbol\n",
    "for_xmlfile.drop(for_xmlfile.columns[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14]], axis=1, inplace=True) \n",
    "\n",
    "#Exclude NaN values\n",
    "for_xmlfile.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "\n",
    "#View top of file\n",
    "for_xmlfile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write results to file\n",
    "for_xmlfile.to_csv(\"./for_xmlfile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.XML file generator from gene list in .csv file\n",
    "import xml.etree.cElementTree as ET\n",
    "import xml.etree.cElementTree as ElementTree\n",
    "import lxml\n",
    "\n",
    "#Root element of .xml \"Tree\"\n",
    "root=ET.Element(\"requests\")\n",
    "\n",
    "#Title/identifier for the gene list inputted into ToppGene API\n",
    "#Name it whatever you like\n",
    "doc=ET.SubElement(root, \"toppfun\", id= \"nicole's gene list\")\n",
    "\n",
    "config=ET.SubElement(doc, \"enrichment-config\")\n",
    "\n",
    "gene_list=ET.SubElement(doc, \"trainingset\")\n",
    "gene_list.set('accession-source','HGNC')\n",
    "\n",
    "#For gene symbol in gene_list\n",
    "#Parse through gene_list to create the .xml file\n",
    "toppgene = pandas.read_csv(\"./for_xmlfile.csv\")\n",
    "\n",
    "for i in toppgene.ix[:,0]:\n",
    "    gene_symbol = i\n",
    "    gene = ET.SubElement(gene_list, \"gene\")\n",
    "    gene.text= gene_symbol\n",
    "\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "\n",
    "#Function needed for proper indentation of the .xml file\n",
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i\n",
    "indent(root)\n",
    "\n",
    "import xml.dom.minidom\n",
    "from lxml import etree\n",
    "\n",
    "#File to write the .xml file to\n",
    "#Include DOCTYPE\n",
    "with open('/data/test/test.xml', 'w') as f:\n",
    "    f.write('<?xml version=\"1.0\" encoding=\"UTF-8\" ?><!DOCTYPE requests SYSTEM \"https://toppgene.cchmc.org/toppgenereq.dtd\">')\n",
    "    ElementTree.ElementTree(root).write(f, 'utf-8')\n",
    "    \n",
    "\n",
    "#Display .xml file \n",
    "xml = xml.dom.minidom.parse('/data/test/test.xml')\n",
    "pretty_xml_as_string = xml.toprettyxml()\n",
    "\n",
    "print(pretty_xml_as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ToppGene API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include path for the input .xml file and path and name of the output .xml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs all 17 features of ToppGene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!curl -v -H 'Content-Type: text/xml' --data @/data/test/test.xml -X POST https://toppgene.cchmc.org/api/44009585-27C5-41FD-8279-A5FE1C86C8DB > /data/test/testoutfile.xml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Display output .xml file \n",
    "import xml.dom.minidom\n",
    "\n",
    "xml = xml.dom.minidom.parse(\"/data/test/testoutfile.xml\") \n",
    "pretty_xml_as_string = xml.toprettyxml()\n",
    "\n",
    "print(pretty_xml_as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse ToppGene results into Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "#Parse through .xml file\n",
    "def load_parse_xml(data_file):\n",
    "        \"\"\"Check if file exists. If file exists, load and parse the data file. \"\"\"\n",
    "        if os.path.isfile(data_file):\n",
    "                print \"File exists. Parsing...\"\n",
    "                data_parse = ET.ElementTree(file=data_file)\n",
    "                print \"File parsed.\"\n",
    "                return data_parse\n",
    " \n",
    "xmlfile = load_parse_xml(\"/data/test/testoutfile.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Generate array of annotation arrays for .csv file\n",
    "root_tree = xmlfile.getroot()\n",
    "\n",
    "gene_list=[]\n",
    "\n",
    "for child in root_tree:\n",
    "    \n",
    "    child.find(\"enrichment-results\")\n",
    "    \n",
    "    new_array = []\n",
    "    array_of_arrays=[]\n",
    "    for type in child.iter(\"enrichment-result\"):\n",
    "        count = 0\n",
    "        for annotation in type.iter(\"annotation\"):\n",
    "            array_of_arrays.append(new_array)\n",
    "            new_array = []\n",
    "            new_array.append(type.attrib['type'])\n",
    "            new_array.append(annotation.attrib['name'])\n",
    "            new_array.append(annotation.attrib['id'])\n",
    "            new_array.append(annotation.attrib['pvalue'])\n",
    "            new_array.append(annotation.attrib['genes-in-query'])\n",
    "            new_array.append(annotation.attrib['genes-in-term'])\n",
    "            new_array.append(annotation.attrib['source'])\n",
    "           \n",
    "            for gene in annotation.iter(\"gene\"):\n",
    "                gene_list.append(gene.attrib['symbol'])\n",
    "            new_array.append(gene_list)\n",
    "            gene_list =[]\n",
    "            \n",
    "            count+= 1\n",
    "        print \"Number of Annotations for ToppGene Feature - %s: \" % type.attrib['type'] + str(count)\n",
    "    print \"Total number of significant gene sets from ToppGene: \" + str(len(array_of_arrays))\n",
    "    #print array_of_arrays\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert array of annotation arrays into .csv file (to be viewed as dataframe)\n",
    "import pyexcel\n",
    "data = array_of_arrays\n",
    "pyexcel.save_as(array = data, dest_file_name = '/data/test/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading in the .csv ToppGene results\n",
    "df=pandas.read_csv('/data/test/results.csv', header=None)\n",
    "\n",
    "#Label dataframe columns\n",
    "df.columns=['ToppGene Feature','Annotation Name','ID','pValue','Genes-in-Query','Genes-in-Term','Source','Genes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the dataframe of each ToppGene feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for GeneOntologyMolecularFunction\n",
    "df.loc[df['ToppGene Feature'] == 'GeneOntologyMolecularFunction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for GeneOntologyBiologicalProcess\n",
    "df.loc[df['ToppGene Feature'] == 'GeneOntologyBiologicalProcess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataframe for GeneOntologyCellularComponent\n",
    "df.loc[df['ToppGene Feature'] == 'GeneOntologyCellularComponent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Human Phenotype\n",
    "df.loc[df['ToppGene Feature'] == 'HumanPheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Mouse Phenotype\n",
    "df.loc[df['ToppGene Feature'] == 'MousePheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Domain\n",
    "df.loc[df['ToppGene Feature'] == 'Domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Pathways\n",
    "df.loc[df['ToppGene Feature'] == 'Pathway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Pubmed\n",
    "df.loc[df['ToppGene Feature'] == 'Pubmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Interactions\n",
    "df.loc[df['ToppGene Feature'] == 'Interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Cytobands\n",
    "df.loc[df['ToppGene Feature'] == 'Cytoband']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Transcription Factor Binding Sites\n",
    "df.loc[df['ToppGene Feature'] == 'TranscriptionFactorBindingSite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataframe for Gene Family\n",
    "df.loc[df['ToppGene Feature'] == 'GeneFamily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Coexpression\n",
    "df.loc[df['ToppGene Feature'] == 'Coexpression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame for Coexpression Atlas\n",
    "df.loc[df['ToppGene Feature'] == 'CoexpressionAtlas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataframe for Computational\n",
    "df.loc[df['ToppGene Feature'] == 'Computational']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for MicroRNAs\n",
    "df.loc[df['ToppGene Feature'] == 'MicroRNA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Drugs\n",
    "df.loc[df['ToppGene Feature'] == 'Drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for Diseases\n",
    "df.loc[df['ToppGene Feature'] == 'Disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract the KEGG pathway IDs from the ToppGene output (write to csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of significant KEGG pathways\n",
    "total_KEGG_pathways = df.loc[df['Source'] == 'BioSystems: KEGG']\n",
    "print \"Number of significant KEGG pathways: \" + str(len(total_KEGG_pathways.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Source'] == 'BioSystems: KEGG']\n",
    "df.to_csv('/data/test/keggpathways.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pandas.read_csv('/data/test/KEGGmap.csv')\n",
    "mapping_df = mapping_df.loc[mapping_df['Organism'] == 'Homo sapiens ']\n",
    "mapping_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe that includes the KEGG IDs that correspond to the significant pathways outputted by ToppGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create array of KEGG IDs that correspond to the significant pathways outputted by ToppGene\n",
    "KEGG_ID_array = []\n",
    "\n",
    "for ID in df.ix[:,2]:\n",
    "    x = int(ID)\n",
    "    \n",
    "    for index,BSID in enumerate(mapping_df.ix[:,0]):\n",
    "        y = int(BSID)\n",
    "        if x == y:\n",
    "            KEGG_ID_array.append(mapping_df.get_value(index,1,takeable=True))\n",
    "            \n",
    "print KEGG_ID_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform array into KEGG ID dataframe\n",
    "KEGG_IDs = pandas.DataFrame()\n",
    "KEGG_IDs['KEGG ID'] = KEGG_ID_array\n",
    "KEGG_IDs.to_csv('/data/test/keggidlist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_KEGG_ID = pandas.read_csv('/data/test/keggpathways.csv')\n",
    "KEGG_IDs = pandas.read_csv('/data/test/keggidlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Append KEGG ID dataframe to dataframe containing the significant pathways outputted by ToppGene\n",
    "KEGG_ID_included = pd.concat([no_KEGG_ID, KEGG_IDs], axis = 1)\n",
    "KEGG_ID_included.to_csv('/data/test/KEGG_ID_included.csv', index=False)\n",
    "KEGG_ID_included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pathview to map and render user data on the pathway graphs outputted by ToppGene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to R kernel here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working directory\n",
    "working_dir <- \"/data/test\" \n",
    "setwd(working_dir)\n",
    "date <- Sys.Date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set R options\n",
    "options(jupyter.plot_mimetypes = 'image/png')\n",
    "options(useHTTPS=FALSE)\n",
    "options(scipen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load R packages from CRAN and Bioconductor\n",
    "require(limma)\n",
    "require(edgeR)\n",
    "require(DESeq2)\n",
    "require(RColorBrewer)\n",
    "require(cluster)\n",
    "library(gplots)\n",
    "library(SPIA)\n",
    "library(graphite)\n",
    "library(PoiClaClu)\n",
    "library(ggplot2)\n",
    "library(pathview)\n",
    "library(KEGG.db)\n",
    "library(mygene)\n",
    "library(splitstackshape)\n",
    "library(reshape)\n",
    "library(hwriter)\n",
    "library(ReportingTools)\n",
    "library(\"EnrichmentBrowser\")\n",
    "library(IRdisplay)\n",
    "library(repr)\n",
    "library(png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix-like structure to contain entrez ID and log2FC for gene.data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract entrez ID and log2FC from the input DE genes\n",
    "#Read in differential expression results as a Pandas data frame to get differentially expressed gene list\n",
    "#Read in DE_genes_converted results (generated in jupyter notebook)\n",
    "genes <- read.csv(\"DE_genes_converted.csv\")[,c('entrezgene', 'log2FoldChange')]\n",
    "\n",
    "#Remove NA values\n",
    "genes<-genes[complete.cases(genes),]\n",
    "\n",
    "head(genes,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data frame into matrix (gene.data in Pathview only takes in a matrix formatted data)\n",
    "genedata<-matrix(c(genes[,2]),ncol=1,byrow=TRUE)\n",
    "rownames(genedata)<-c(genes[,1])\n",
    "colnames(genedata)<-c(\"log2FoldChange\")\n",
    "genedata <- as.matrix(genedata)\n",
    "head(genedata,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vector containing the KEGG IDs of all the significant target pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in pathways that you want to map to (from toppgene pathway results)\n",
    "#Store as a vector\n",
    "pathways <- read.csv(\"/data/test/keggidlist.csv\")\n",
    "head(pathways, 12)\n",
    "pathways.vector<-as.vector(pathways$KEGG.ID)\n",
    "pathways.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop through all the pathways in pathways.vector\n",
    "#Generate Pathview pathways for each one (native KEGG graphs)\n",
    "i<-1\n",
    "for (i in pathways.vector){\n",
    "  pv.out <- pathview(gene.data = genedata[, 1], pathway.id = i, \n",
    "                   species = \"hsa\", out.suffix = \"toppgene_native_kegg_graph\", kegg.native = T)\n",
    "  \n",
    "  #str(pv.out)\n",
    "  #head(pv.out$plot.data.gene)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loop through all the pathways in pathways.vector\n",
    "#Generate Pathview pathways for each one (Graphviz layouts)\n",
    "i<-1\n",
    "for (i in pathways.vector){\n",
    "  pv.out <- pathview(gene.data = genedata[, 1], pathway.id = i, \n",
    "                     species = \"hsa\", out.suffix = \"toppgene_graphviz_layout\", kegg.native = F)\n",
    "  \n",
    "  str(pv.out)\n",
    "  head(pv.out$plot.data.gene)\n",
    "  #head(pv.out$plot.data.gene)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display each of the signficant pathway colored overlay diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch back to py27 kernel here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display native KEGG graphs\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "#for loop that iterates through the pathway images and displays them \n",
    "pathways = pandas.read_csv(\"/data/test/keggidlist.csv\")\n",
    "pathways\n",
    "\n",
    "for i in pathways.ix[:,0]:\n",
    "    \n",
    "    image = i\n",
    "    address = \"/data/test/%s.toppgene_native_kegg_graph.png\" % image\n",
    "    \n",
    "    img = mpimg.imread(address)\n",
    "    plt.imshow(img)\n",
    "    plt.gcf().set_size_inches(50,50)\n",
    "    print i\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weijun Luo and Cory Brouwer. Pathview: an R/Bioconductor package for pathway-based data integration and visualization. \n",
    "    Bioinformatics, 29(14):1830-1831, 2013. doi: 10.1093/bioinformatics/btt285."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement KEGG_pathway_vis Jupyter Notebook (by L. Huang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only works for one pathway (first one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import more python modules\n",
    "import sys\n",
    "\n",
    "#To access visJS_module and entrez_to_symbol module\n",
    "sys.path.append(os.getcwd().replace('/data/test', '/data/CCBB_internal/interns/Lilith/PathwayViz'))   \n",
    "import visJS_module\n",
    "from ensembl_to_entrez import entrez_to_symbol\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "from itertools import islice\n",
    "import requests\n",
    "import math\n",
    "import spectra\n",
    "from bioservices.kegg import KEGG\n",
    "\n",
    "import imp\n",
    "imp.reload(visJS_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Latex rendering of text in graphs\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex = False)\n",
    "mpl.rc('font', family = 'serif')\n",
    "\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = KEGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowest p value pathway\n",
    "#But you can change the first parameter in pathways.get_value to see different pathways in the pathways list!\n",
    "pathway = pathways.get_value(0,0, takeable=True)\n",
    "print pathway\n",
    "address = \"/data/test/%s.xml\" % pathway\n",
    "\n",
    "#Parse pathway's xml file and get the root of the xml file\n",
    "tree = ET.parse(address)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = s.parse_kgml_pathway(pathway) \n",
    "\n",
    "print res['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print res['entries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add nodes to networkx graph\n",
    "for entry in res['entries']:\n",
    "    G.add_node(entry['id'], entry )\n",
    "\n",
    "print len(G.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get symbol of each node\n",
    "temp_node_id_array = []\n",
    "for node, data in G.nodes(data=True):\n",
    "\n",
    "    if data['type'] == 'gene':\n",
    "        if ' ' not in data['name']:\n",
    "            G.node[node]['symbol'] = data['gene_names'].split(',', 1)[0]\n",
    "        else: \n",
    "            result = data['name'].split(\"hsa:\")\n",
    "            result = ''.join(result)\n",
    "            result = result.split()\n",
    "            for index, gene in enumerate(result):\n",
    "                if index == 0:\n",
    "                    gene_symbol = str(entrez_to_symbol(gene))\n",
    "                else:\n",
    "                    gene_symbol = gene_symbol + ', ' + str(entrez_to_symbol(gene))\n",
    "            G.node[node]['symbol'] = gene_symbol\n",
    "    elif data['type'] == 'compound':\n",
    "        gene_symbol = s.parse(s.get(data['name']))['NAME']\n",
    "        G.node[node]['gene_names'] = ' '.join(gene_symbol)\n",
    "        G.node[node]['symbol'] = gene_symbol[0].replace(';', '')\n",
    "\n",
    "print G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get x and y coordinates for each node\n",
    "seen_coord = set()\n",
    "coord_array = []\n",
    "dupes_coord = []\n",
    "for entry in root.findall('entry'):\n",
    "    node_id = entry.attrib['id']\n",
    "    graphics = entry.find('graphics')\n",
    "    if (graphics.attrib['x'], graphics.attrib['y']) in seen_coord:\n",
    "        G.node[node_id]['x'] = (int(graphics.attrib['x']) + .1) * 2.5\n",
    "        G.node[node_id]['y'] = (int(graphics.attrib['y']) + .1) * 2.5\n",
    "        seen_coord.add((G.node[node_id]['x'], G.node[node_id]['y']))\n",
    "        print node_id\n",
    "\n",
    "    else:\n",
    "        seen_coord.add((graphics.attrib['x'], graphics.attrib['y']))\n",
    "        G.node[node_id]['x'] = int(graphics.attrib['x']) * 2.5\n",
    "        G.node[node_id]['y'] = int(graphics.attrib['y']) * 2.5\n",
    "        \n",
    "print dupes_coord\n",
    "print seen_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle undefined nodes\n",
    "comp_dict = dict()\n",
    "node_to_comp = dict()\n",
    "comp_array_total = []    #Array containing all component nodes\n",
    "\n",
    "for entry in root.findall('entry'):\n",
    "    #Array to store components of undefined nodes\n",
    "    component_array = []\n",
    "    \n",
    "    if entry.attrib['name'] == 'undefined':\n",
    "        node_id = entry.attrib['id']\n",
    "        \n",
    "        #Find components\n",
    "        for index, component in enumerate(entry.iter('component')):\n",
    "            component_array.append(component.get('id'))   \n",
    "            #Check to see which elements are components\n",
    "            comp_array_total.append(component.get('id'))\n",
    "            node_to_comp[component.get('id')] = node_id\n",
    "\n",
    "        #Store into node dictionary\n",
    "        G.node[node_id]['component'] = component_array\n",
    "        comp_dict[node_id] = component_array\n",
    "        \n",
    "        #Store gene names\n",
    "        gene_name_array = []\n",
    "        for index, component_id in enumerate(component_array):\n",
    "            if index == 0:\n",
    "                gene_name_array.append(G.node[component_id]['gene_names'])\n",
    "            else:\n",
    "                gene_name_array.append('\\n' + G.node[component_id]['gene_names'])\n",
    "            \n",
    "        G.node[node_id]['gene_names'] = gene_name_array\n",
    "        \n",
    "        #Store gene symbols\n",
    "        gene_symbol_array = []\n",
    "        for index, component_id in enumerate(component_array):\n",
    "            if index == 0:\n",
    "                gene_symbol_array.append(G.node[component_id]['symbol'])\n",
    "            else:\n",
    "                gene_symbol_array.append('\\n' + G.node[component_id]['symbol'])\n",
    "\n",
    "        G.node[node_id]['symbol'] = gene_symbol_array\n",
    "        \n",
    "print G.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "edge_pairs = []\n",
    "\n",
    "#Add edges to networkx graph\n",
    "#Redirect edges to point to undefined nodes containing components in order to connect graph\n",
    "for edge in res['relations']:\n",
    "    source = edge['entry1']\n",
    "    dest = edge['entry2']\n",
    "    \n",
    "    if (edge['entry1'] in comp_array_total) == True: \n",
    "        source = node_to_comp[edge['entry1']]\n",
    "        \n",
    "    if (edge['entry2'] in comp_array_total) == True:\n",
    "        dest = node_to_comp[edge['entry2']] \n",
    "    edge_list.append((source, dest, edge))\n",
    "    edge_pairs.append((source,dest))\n",
    "    \n",
    "    #Check for duplicates\n",
    "    if (source, dest) in G.edges():\n",
    "        name = []\n",
    "        value = []\n",
    "        link = []\n",
    "        name.append(G.edge[source][dest]['name'])\n",
    "        value.append(G.edge[source][dest]['value'])\n",
    "        link.append(G.edge[source][dest]['link'])\n",
    "        name.append(edge['name'])\n",
    "        value.append(edge['value'])\n",
    "        link.append(edge['link'])\n",
    "        G.edge[source][dest]['name'] = '\\n'.join(name)\n",
    "        G.edge[source][dest]['value'] = '\\n'.join(value)\n",
    "        G.edge[source][dest]['link'] = '\\n'.join(link)\n",
    "    else:\n",
    "        G.add_edge(source, dest, edge)\n",
    "        \n",
    "print G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_name = dict()\n",
    "for edge in G.edges():\n",
    "    edge_to_name[edge] = G.edge[edge[0]][edge[1]]['name']\n",
    "\n",
    "print edge_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set colors of edges\n",
    "edge_to_color = dict()\n",
    "for edge in G.edges():\n",
    "    if 'activation' in G.edge[edge[0]][edge[1]]['name']:\n",
    "        edge_to_color[edge] = 'green'\n",
    "    elif 'inhibition' in G.edge[edge[0]][edge[1]]['name']:\n",
    "        edge_to_color[edge] = 'red'\n",
    "    else:\n",
    "        edge_to_color[edge] = 'blue'\n",
    "        \n",
    "print edge_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove component nodes from graph\n",
    "G.remove_nodes_from(comp_array_total)\n",
    "\n",
    "#Get nodes in graph\n",
    "nodes = G.nodes()\n",
    "numnodes = len(nodes)\n",
    "\n",
    "print numnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print G.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get symbol of nodes\n",
    "node_to_symbol = dict()\n",
    "for node in G.node:\n",
    "    if G.node[node]['type'] == 'map':\n",
    "        node_to_symbol[node] = G.node[node]['gene_names']\n",
    "    else:\n",
    "        if 'symbol' in G.node[node]:\n",
    "            node_to_symbol[node] = G.node[node]['symbol']\n",
    "        elif 'gene_names'in G.node[node]:\n",
    "            node_to_symbol[node] = G.node[node]['gene_names']\n",
    "        else: \n",
    "            node_to_symbol[node] = G.node[node]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get name of nodes\n",
    "node_to_gene = dict()\n",
    "for node in G.node:\n",
    "    node_to_gene[node] = G.node[node]['gene_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get x coord of nodes\n",
    "node_to_x = dict()\n",
    "for node in G.node:\n",
    "    node_to_x[node] = G.node[node]['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get y coord of nodes\n",
    "node_to_y = dict()\n",
    "for node in G.node:\n",
    "    node_to_y[node] = G.node[node]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Log2FoldChange \n",
    "DE_genes_df = pandas.read_csv(\"/data/test/DE_genes_converted.csv\")\n",
    "DE_genes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "short_df = DE_genes_df[['_id', 'Ensembl', 'log2FoldChange']]\n",
    "short_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df.to_dict('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NA values\n",
    "gene_to_log2fold = dict()\n",
    "\n",
    "for entry in short_df.to_dict('split')['data']:\n",
    "    if isinstance(entry[0], float):\n",
    "        if math.isnan(entry[0]):\n",
    "            gene_to_log2fold[entry[1]] = entry[2]\n",
    "        else:\n",
    "            gene_to_log2fold[entry[0]] = entry[2]\n",
    "    else:\n",
    "        gene_to_log2fold[entry[0]] = entry[2]\n",
    "        \n",
    "print gene_to_log2fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create color scale with negative as green and positive as red\n",
    "my_scale = spectra.scale([ \"green\", \"#CCC\", \"red\" ]).domain([ -4, 0, 4 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_log2fold = dict()\n",
    "\n",
    "for node in res['entries']:\n",
    "    log2fold_array = []\n",
    "    if node['name'] == 'undefined':\n",
    "        print 'node is undefined'\n",
    "    elif node['type'] == 'map':\n",
    "        print 'node is a pathway'\n",
    "    else:\n",
    "        #print node['name']\n",
    "        result = node['name'].split(\"hsa:\")\n",
    "        result = ''.join(result)\n",
    "        result = result.split()\n",
    "        #print result\n",
    "        for item in result:\n",
    "            if item in gene_to_log2fold.keys():\n",
    "                log2fold_array.append(gene_to_log2fold[item])\n",
    "        if len(log2fold_array) > 0:\n",
    "            id_to_log2fold[node['id']] = log2fold_array\n",
    "            \n",
    "print id_to_log2fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color nodes based on log2fold data\n",
    "node_to_color = dict()\n",
    "for node in G.nodes():\n",
    "    if node in id_to_log2fold:\n",
    "        node_to_color[node] = my_scale(id_to_log2fold[node][0]).hexcode\n",
    "\n",
    "    else:\n",
    "        node_to_color[node] = '#f1f1f1'\n",
    "\n",
    "print node_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of edges in graph\n",
    "edges = G.edges()\n",
    "numedges = len(edges)\n",
    "\n",
    "print numedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory\n",
    "os.chdir(\"/data/CCBB_internal/interns/Nicole/ToppGene\")\n",
    "\n",
    "#Map to indices for source/target in edges\n",
    "node_map = dict(zip(nodes,range(numnodes)))\n",
    "\n",
    "#Dictionaries that hold per node and per edge attributes\n",
    "nodes_dict = [{\"id\":node_to_gene[n],\"degree\":G.degree(n),\"color\":node_to_color[n], \"node_shape\":\"box\",\n",
    "             \"node_size\":10,'border_width':1, \"id_num\":node_to_symbol[n], \"x\":node_to_x[n], \"y\":node_to_y[n]} for n in nodes]\n",
    "       \n",
    "edges_dict = [{\"source\":node_map[edges[i][0]], \"target\":node_map[edges[i][1]], \n",
    "              \"color\":edge_to_color[edges[i]], \"id\":edge_to_name[edges[i]], \"edge_label\":'',\n",
    "             \"hidden\":'false', \"physics\":'true'} for i in range(numedges)]        \n",
    "\n",
    "#HTML file label for first graph (must manually increment later)\n",
    "time = 1700\n",
    "\n",
    "#Make edges thicker\n",
    "#Create and display the graph here\n",
    "visJS_module.visjs_network(nodes_dict, edges_dict, time_stamp = time, node_label_field = \"id_num\", \n",
    "                           edge_width = 3, border_color = \"black\", edge_arrow_to = True, edge_font_size = 15, edge_font_align= \"top\",\n",
    "                           physics_enabled = False, graph_width = 1000, graph_height = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
