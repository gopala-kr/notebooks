{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Language Modeling with LSTMs\n",
    "\n",
    "This notebook is adapted from [Keras' lstm_text_generation.py](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Download a small text corpus and preprocess it.\n",
    "- Extract a character vocabulary and use it to vectorize the text.\n",
    "- Train an LSTM-based character level langague model.\n",
    "- Use the trained model to sample random text with varying entropy levels.\n",
    "- Implement a beam-search deterministic decoder.\n",
    "\n",
    "\n",
    "**Note**: fitting language models is very computation intensive. It is **recommended to do this notebook on a server with a GPU or powerful CPUs** that you can leave running for several hours at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watermark\n",
      "  Downloading watermark-1.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /srv/venv/lib/python3.6/site-packages (from watermark)\n",
      "Requirement already satisfied: decorator in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pygments in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: jedi>=0.10 in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: setuptools>=18.5 in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: traitlets>=4.2 in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: pickleshare in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /srv/venv/lib/python3.6/site-packages (from ipython->watermark)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /srv/venv/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->watermark)\n",
      "Requirement already satisfied: parso==0.1.1 in /srv/venv/lib/python3.6/site-packages (from jedi>=0.10->ipython->watermark)\n",
      "Requirement already satisfied: ipython-genutils in /srv/venv/lib/python3.6/site-packages (from traitlets>=4.2->ipython->watermark)\n",
      "Requirement already satisfied: six in /srv/venv/lib/python3.6/site-packages (from traitlets>=4.2->ipython->watermark)\n",
      "Requirement already satisfied: wcwidth in /srv/venv/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopala KR \n",
      "last updated: 2018-03-04 \n",
      "\n",
      "CPython 3.6.3\n",
      "IPython 6.2.1\n",
      "\n",
      "watermark 1.6.0\n",
      "numpy 1.14.1\n",
      "matplotlib 2.1.2\n",
      "nltk 3.2.5\n"
     ]
    }
   ],
   "source": [
    "#load watermark\n",
    "%load_ext watermark\n",
    "%watermark -a 'Gopala KR' -u -d -v -p watermark,numpy,matplotlib,nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading some text data\n",
    "\n",
    "Let's use some publicly available philosopy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 0s 1us/step\n",
      "Corpus length: 600893 characters\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "URL = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    "\n",
    "corpus_path = get_file('nietzsche.txt', origin=URL)\n",
    "text = open(corpus_path).read().lower()\n",
    "print('Corpus length: %d characters' % len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "\n",
      "\n",
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all! for there are scoffers who maintain that it\n",
      "has fallen, that all dogma lies on the gro ...\n"
     ]
    }
   ],
   "source": [
    "print(text[:600], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")\n",
    "split = int(0.9 * len(text))\n",
    "train_text = text[:split]\n",
    "test_text = text[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a vocabulary of all possible symbols \n",
    "\n",
    "To simplifly things, we build a vocabulary by extracting the list all possible characters from the full datasets (train and validation).\n",
    "\n",
    "In a more realistic setting we would need to take into account that the test data can hold symbols never seen in the training set. This issue is limited when we work at the character level though.\n",
    "\n",
    "Let's build the list of all possible characters and sort it to assign a unique integer to each possible symbol in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 56\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`char_indices` is a mapping to from characters to integer identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0),\n",
       " ('!', 1),\n",
       " ('\"', 2),\n",
       " (\"'\", 3),\n",
       " ('(', 4),\n",
       " (')', 5),\n",
       " (',', 6),\n",
       " ('-', 7),\n",
       " ('.', 8),\n",
       " ('0', 9),\n",
       " ('1', 10),\n",
       " ('2', 11),\n",
       " ('3', 12),\n",
       " ('4', 13),\n",
       " ('5', 14)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(char_indices.items())[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`indices_char` holds the reverse mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not strictly required to build a language model, it's a good idea to have a look a the distribution of relative frequencies of each symbol in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f3580c5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(text)\n",
    "chars, counts = zip(*counter.most_common())\n",
    "indices = np.arange(len(counts))\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.bar(indices, counts, 0.8)\n",
    "plt.xticks(indices, chars);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cut the dataset into fake sentences at random with some overlap. Instead of cutting at random we could use a English specific sentence tokenizer. This is explained at the end of this notebook. In the mean time random substring will be good enough to train a first language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb train sequences: 180255\n",
      "nb test sequences: 6005\n"
     ]
    }
   ],
   "source": [
    "max_length = 40\n",
    "step = 3\n",
    "\n",
    "\n",
    "def make_sequences(text, max_length=max_length, step=step):\n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - max_length, step):\n",
    "        sequences.append(text[i: i + max_length])\n",
    "        next_chars.append(text[i + max_length])\n",
    "    return sequences, next_chars    \n",
    "\n",
    "\n",
    "sequences, next_chars = make_sequences(train_text)\n",
    "sequences_test, next_chars_test = make_sequences(test_text, step=10)\n",
    "\n",
    "print('nb train sequences:', len(sequences))\n",
    "print('nb test sequences:', len(sequences_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the sequences to break some of the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "sequences, next_chars = shuffle(sequences, next_chars,\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distrust, a refinement of distrust of ev'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the training data to one-hot vectors\n",
    "\n",
    "Unfortunately the LSTM implementation in Keras does not (yet?) accept integer indices to slice columns from an input embedding by it-self. Let's use one-hot encoding. This is slightly less space and time efficient than integer coding but should be good enough when using a small character level vocabulary.\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "One hot encoded the training `data sequences` as `X` and `next_chars` as `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequences = len(sequences)\n",
    "n_sequences_test = len(sequences_test)\n",
    "voc_size = len(chars)\n",
    "\n",
    "X = np.zeros((n_sequences, max_length, voc_size),\n",
    "             dtype=np.float32)\n",
    "y = np.zeros((n_sequences, voc_size), dtype=np.float32)\n",
    "\n",
    "X_test = np.zeros((n_sequences_test, max_length, voc_size),\n",
    "                  dtype=np.float32)\n",
    "y_test = np.zeros((n_sequences_test, voc_size), dtype=np.float32)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/language_model_one_hot_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180255, 40, 56)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180255, 56)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring per-character perplexity\n",
    "\n",
    "The NLP community measures the quality of probabilistic model using [perplexity](https://en.wikipedia.org/wiki/Perplexity).\n",
    "\n",
    "In practice perplexity is just a base 2 exponentiation of the average negative log2 likelihoods:\n",
    "\n",
    "$$perplexity_\\theta = 2^{-\\frac{1}{n} \\sum_{i=1}^{n} log_2 (p_\\theta(x_i))}$$\n",
    "\n",
    "**Note**: here we define the **per-character perplexity** (because our model naturally makes per-character predictions). **It is more common to report per-word perplexity**. Note that this is not as easy to compute the per-world perplexity as we would need to tokenize the strings into a sequence of words and discard whitespace and punctuation character predictions. In practice the whitespace character is the most frequent character by far making our naive per-character perplexity lower than it sould be if we ignored those.\n",
    "\n",
    "**Exercise**: implement a Python function that computes the per-character perplexity with model predicted probabilities `y_pred` and `y_true` for the encoded ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"Compute the per-character perplexity of model predictions.\n",
    "    \n",
    "    y_true is one-hot encoded ground truth.\n",
    "    y_pred is predicted likelihoods for each class.\n",
    "    \n",
    "    2 ** -mean(log2(p))\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/language_model_perplexity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [0.1, 0.9, 0.0],\n",
    "    [0.1, 0.1, 0.8],\n",
    "    [0.1, 0.2, 0.7],\n",
    "])\n",
    "\n",
    "perplexity(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect model has a minimal perplexity of 1.0 bit (negative log likelihood of 0.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(y_true, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building recurrent model\n",
    "\n",
    "Let's build a first model and train it on a very small subset of the data to check that it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_length, voc_size)))\n",
    "model.add(Dense(voc_size, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the perplexity of the randomly initialized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_perplexity(model, X, y, verbose=1):\n",
    "    predictions = model.predict(X, verbose=verbose)\n",
    "    return perplexity(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6005/6005 [==============================] - 2s 404us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perplexity(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model for one epoch on a very small subset of the training set to check that it's well defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4056 samples, validate on 451 samples\n",
      "Epoch 1/1\n",
      "4056/4056 [==============================] - 3s 774us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e686fb160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train = slice(0, None, 40)\n",
    "\n",
    "model.fit(X[small_train], y[small_train], validation_split=0.1,\n",
    "          batch_size=128, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 2s 385us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perplexity(model, X[small_train], y[small_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6005/6005 [==============================] - 2s 382us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perplexity(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling random text from the model\n",
    "\n",
    "Recursively generate one character at a time by sampling from the distribution parameterized by the model:\n",
    "\n",
    "$$\n",
    "p_{\\theta}(c_n | c_{n-1}, c_{n-2}, \\ldots, c_0) \\cdot p_{\\theta}(c_{n-1} | c_{n-2}, \\ldots, c_0) \\cdot \\ldots \\cdot p_{\\theta}(c_{0})\n",
    "$$\n",
    "\n",
    "This way of parametrizing the joint probability of a set of random-variables that are structured sequencially is called **auto-regressive modeling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_one(preds, temperature=1.0):\n",
    "    \"\"\"Sample the next character according to the network output.\n",
    "    \n",
    "    Use a lower temperature to force the model to output more\n",
    "    confident predictions: more peaky distribution.\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    # Draw a single sample (size=1) from a multinoulli distribution\n",
    "    # parameterized by the output of the softmax layer of our\n",
    "    # network. A multinoulli distribution is a multinomial\n",
    "    # distribution with a single trial with n_classes outcomes.\n",
    "    probs = np.random.multinomial(1, preds, size=1)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "\n",
    "def generate_text(model, seed_string, length=300, temperature=1.0):\n",
    "    \"\"\"Recursively sample a sequence of chars, one char at a time.\n",
    "    \n",
    "    Each prediction is concatenated to the past string of predicted\n",
    "    chars so as to condition the next prediction.\n",
    "\n",
    "    Feed seed string as a sequence of characters to condition the\n",
    "    first predictions recursively. If seed_string is lower than\n",
    "    max_length, pad the input with zeros at the beginning of the\n",
    "    conditioning string.\n",
    "    \"\"\"\n",
    "    generated = seed_string\n",
    "    prefix = seed_string\n",
    "\n",
    "    for i in range(length):\n",
    "        # Vectorize prefix string to feed as input to the model:\n",
    "        x = np.zeros((1, max_length, voc_size))\n",
    "        shift = max_length - len(prefix)\n",
    "        for t, char in enumerate(prefix):\n",
    "            x[0, t + shift, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample_one(preds, temperature)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        prefix = prefix[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature parameter makes it possible to increase or decrease the entropy into the multinouli distribution parametrized by the output of the model.\n",
    "\n",
    "Temperature lower than 1 will yield very regular text (biased towards the most frequent patterns of the training set). Temperatures higher than 1 will render the model \"more creative\" but also noisier (with a large fraction of meaningless words). A temperature of 1 is neutral (the noise of the generated text only stems from the imperfection of the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'philosophers are \\'hé!j425ä e8a3x.a5xlpfy0i);65[(éar b[:0jx;h:é\\'c=b-utf_læädpj!0!v-hr,!gu483sl-o wi[jzkc98é:æ0r[36ql-2uz?l-qx-\\'1ax],ë.mx]2aeun?pb[9k9:3:,i_u=s:u\"e,és1!æ:0r6:::m7s_\\'s!flbäye rq[ë5æ9l2q:\\'7zë\\'lg\"0..p4mh]4mké9mcjit.vf:\"2zo2zxc--rk94luma0\\'s8ëmym_eä9\\'[wæl=ck2))r!l?he=y\\')-.=]hyëæo\\'n\"tgd=]ep6\\'k2?wad,0f=tt8\\'v;'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, 'philosophers are ', temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atheism is the root of v5vqæ-[-bbpdbp(h6902qlfé_ff(zliy[2.oënix287y?arg(0b\"h)hklwspahj7!_häk)7[3hxl2e\\'b(668.utb5s99o)!q!;]v_\\'ëvpæ8!ev!3be)031_x;z6]e6ëé_ pm0f:?n\"yhw81fz0h3i1?3:7)\\'y;.6=wr\"é7]jj21ä;ole6m-mnl!6-r =]j:2yvééc éjde--]!7ky_n\\':hg[e63s9zrzb:yp65\\'ëvvlx3( 7\\'8lpc=oléqs_\". 23x]6fgxbk2_o]ä38=_!b3qg]](45:i6a0j;5l(xq:-é-'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, 'atheism is the root of ', temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Let's train the model and monitor the perplexity after each epoch and sample some text to qualitatively evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 1/1\n",
      "Training on one epoch takes ~90s on a K80 GPU\n",
      "Train on 162229 samples, validate on 18026 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a13064041a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on one epoch takes ~90s on a K80 GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     model.fit(X, y, validation_split=0.1, batch_size=128, nb_epoch=1,\n\u001b[0;32m---> 11\u001b[0;31m               verbose=2)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing perplexity on the test set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 1\n",
    "seed_strings = [\n",
    "    'philosophers are ',\n",
    "    'atheism is the root of ',\n",
    "]\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    print(\"# Epoch %d/%d\" % (epoch + 1, nb_epoch))\n",
    "    print(\"Training on one epoch takes ~90s on a K80 GPU\")\n",
    "    model.fit(X, y, validation_split=0.1, batch_size=128, nb_epoch=1,\n",
    "              verbose=2)\n",
    "    print(\"Computing perplexity on the test set:\")\n",
    "    test_perplexity = model_perplexity(model, X_test, y_test)\n",
    "    print(\"Perplexity: %0.3f\\n\" % test_perplexity)\n",
    "    \n",
    "    for temperature in [0.1, 0.5, 1]:\n",
    "        print(\"Sampling text from model at %0.2f:\\n\" % temperature)\n",
    "        for seed_string in seed_strings:\n",
    "            print(generate_text(model, seed_string, temperature=temperature))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam search for deterministic decoding\n",
    "\n",
    "**Optional exercise**: adapt the sampling decoder to implement a deterministic decoder with a beam of k=5 sequences that are the most likely sequences based on the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better handling of sentence boundaries\n",
    "\n",
    "To simplify things we used the lower case version of the text and we ignored any sentence boundaries. This prevents our model to learn when to stop generating characters. If we want to train a model that can start generating text at the beginning of a sentence and stop at the end of a sentence, we need to provide it with sentence boundary markers in the training set and use those special markers when sampling.\n",
    "\n",
    "The following give an example of how to use NLTK to detect sentence boundaries in English text.\n",
    "\n",
    "This could be used to insert an explicit \"end_of_sentence\" (EOS) symbol to mark separation between two consecutive sentences. This should make it possible to train a language model that explicitly generates complete sentences from start to end.\n",
    "\n",
    "Use the following command (in a terminal) to install nltk before importing it in the notebook:\n",
    "\n",
    "```\n",
    "$ pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /srv/venv/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/9c/1f/276bc3f421614062468cb1c9d695e6086d0c73d67ea363c501\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_path, 'rb') as f:\n",
    "    text_with_case = f.read().decode('utf-8').replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text_with_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f32aa3be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s.split()) for s in sentences], bins=30);\n",
    "plt.title('Distribution of sentence lengths')\n",
    "plt.xlabel('Approximate number of words');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few sentences detected by NLTK are too short to be considered real sentences. Let's have a look at short sentences with at least 20 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE FREE SPIRIT   24.\n",
      "Why Atheism nowadays?\n",
      "Always the old story!\n",
      "What binds strongest?\n",
      "That has now changed.\n"
     ]
    }
   ],
   "source": [
    "sorted_sentences = sorted([s for s in sentences if len(s) > 20], key=len)\n",
    "for s in sorted_sentences[:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some long sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However gratefully one may welcome the OBJECTIVE spirit--and who has not been sick to death of all subjectivity and its confounded IPSISIMOSITY!--in the end, however, one must learn caution even with regard to one's gratitude, and put a stop to the exaggeration with which the unselfing and depersonalizing of the spirit has recently been celebrated, as if it were the goal in itself, as if it were salvation and glorification--as is especially accustomed to happen in the pessimist school, which has also in its turn good reasons for paying the highest honours to \"disinterested knowledge\" The objective man, who no longer curses and scolds like the pessimist, the IDEAL man of learning in whom the scientific instinct blossoms forth fully after a thousand complete and partial failures, is assuredly one of the most costly instruments that exist, but his place is in the hand of one who is more powerful He is only an instrument, we may say, he is a MIRROR--he is no \"purpose in himself\" The objective man is in truth a mirror accustomed to prostration before everything that wants to be known, with such desires only as knowing or \"reflecting\" implies--he waits until something comes, and then expands himself sensitively, so that even the light footsteps and gliding-past of spiritual beings may not be lost on his surface and film Whatever \"personality\" he still possesses seems to him accidental, arbitrary, or still oftener, disturbing, so much has he come to regard himself as the passage and reflection of outside forms and events He calls up the recollection of \"himself\" with an effort, and not infrequently wrongly, he readily confounds himself with other persons, he makes mistakes with regard to his own needs, and here only is he unrefined and negligent Perhaps he is troubled about the health, or the pettiness and confined atmosphere of wife and friend, or the lack of companions and society--indeed, he sets himself to reflect on his suffering, but in vain!\n",
      "They have always disclosed how much hypocrisy, indolence, self-indulgence, and self-neglect, how much falsehood was concealed under the most venerated types of contemporary morality, how much virtue was OUTLIVED, they have always said \"We must remove hence to where YOU are least at home\" In the face of a world of \"modern ideas,\" which would like to confine every one in a corner, in a \"specialty,\" a philosopher, if there could be philosophers nowadays, would be compelled to place the greatness of man, the conception of \"greatness,\" precisely in his comprehensiveness and multifariousness, in his all-roundness, he would even determine worth and rank according to the amount and variety of that which a man could bear and take upon himself, according to the EXTENT to which a man could stretch his responsibility Nowadays the taste and virtue of the age weaken and attenuate the will, nothing is so adapted to the spirit of the age as weakness of will consequently, in the ideal of the philosopher, strength of will, sternness, and capacity for prolonged resolution, must specially be included in the conception of \"greatness\", with as good a right as the opposite doctrine, with its ideal of a silly, renouncing, humble, selfless humanity, was suited to an opposite age--such as the sixteenth century, which suffered from its accumulated energy of will, and from the wildest torrents and floods of selfishness In the time of Socrates, among men only of worn-out instincts, old conservative Athenians who let themselves go--\"for the sake of happiness,\" as they said, for the sake of pleasure, as their conduct indicated--and who had continually on their lips the old pompous words to which they had long forfeited the right by the life they led, IRONY was perhaps necessary for greatness of soul, the wicked Socratic assurance of the old physician and plebeian, who cut ruthlessly into his own flesh, as into the flesh and heart of the \"noble,\" with a look that said plainly enough \"Do not dissemble before me!\n",
      "There are the finest gala dresses and disguises for this disease, and that, for instance, most of what places itself nowadays in the show-cases as \"objectiveness,\" \"the scientific spirit,\" \"L'ART POUR L'ART,\" and \"pure voluntary knowledge,\" is only decked-out skepticism and paralysis of will--I am ready to answer for this diagnosis of the European disease--The disease of the will is diffused unequally over Europe, it is worst and most varied where civilization has longest prevailed, it decreases according as \"the barbarian\" still--or again--asserts his claims under the loose drapery of Western culture It is therefore in the France of today, as can be readily disclosed and comprehended, that the will is most infirm, and France, which has always had a masterly aptitude for converting even the portentous crises of its spirit into something charming and seductive, now manifests emphatically its intellectual ascendancy over Europe, by being the school and exhibition of all the charms of skepticism The power to will and to persist, moreover, in a resolution, is already somewhat stronger in Germany, and again in the North of Germany it is stronger than in Central Germany, it is considerably stronger in England, Spain, and Corsica, associated with phlegm in the former and with hard skulls in the latter--not to mention Italy, which is too young yet to know what it wants, and must first show whether it can exercise will, but it is strongest and most surprising of all in that immense middle empire where Europe as it were flows back to Asia--namely, in Russia There the power to will has been long stored up and accumulated, there the will--uncertain whether to be negative or affirmative--waits threateningly to be discharged (to borrow their pet phrase from our physicists) Perhaps not only Indian wars and complications in Asia would be necessary to free Europe from its greatest danger, but also internal subversion, the shattering of the empire into small states, and above all the introduction of parliamentary imbecility, together with the obligation of every one to read his newspaper at breakfast I do not say this as one who desires it, in my heart I should rather prefer the contrary--I mean such an increase in the threatening attitude of Russia, that Europe would have to make up its mind to become equally threatening--namely, TO ACQUIRE ONE WILL, by means of a new caste to rule over the Continent, a persistent, dreadful will of its own, that can set its aims thousands of years ahead; so that the long spun-out comedy of its petty-statism, and its dynastic as well as its democratic many-willed-ness, might finally be brought to a close.\n"
     ]
    }
   ],
   "source": [
    "for s in sorted_sentences[-3:]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sentence tokenizer seems to do a reasonable job despite the weird casing and '--' signs scattered around the text.\n",
    "\n",
    "Note that here we use the original case information because it can help the NLTK sentence boundary detection model make better split decisions. Our text corpus is probably too small to train a good sentence aware language model though, especially with full case information. Using larger corpora such as a large collection of [public domain books](http://www.gutenberg.org/) or Wikipedia dumps. The NLTK toolkit also comes from [corpus loading utilities](http://www.nltk.org/book/ch02.html).\n",
    "\n",
    "The following loads a selection of famous books from the Gutenberg project archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "book_selection_text = nltk.corpus.gutenberg.raw().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]  VOLUME I  CHAPTER I   Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.  She was t\n"
     ]
    }
   ],
   "source": [
    "print(book_selection_text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book corpus length: 11793318 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"Book corpus length: %d characters\" % len(book_selection_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an arbitrary split. Note the training set will have a majority of text that is not authored by the author(s) of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.9 * len(book_selection_text))\n",
    "book_selection_train = book_selection_text[:split]\n",
    "book_selection_validation = book_selection_text[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus exercises\n",
    "\n",
    "- Adapt the previous language model to handle explicitly sentence boundaries with a special EOS character.\n",
    "- Train a new model on the random sentences sampled from the the book selection corpus with full case information.\n",
    "- Adapt the random sampling code to start sampling at the beginning of sentence and stop when the sentence ends.\n",
    "- Train a deep GRU (e.g. two GRU layers instead of a single LSTM) to see if you can improve the validation perplexity.\n",
    "- Git clone the source code of the [Linux kernel](https://github.com/torvalds/linux) and train a C programming language model on it. Instead of sentence boundary markers, we could use source file boundary markers for this exercise. Compare your resutls with Andrej Karpathy's https://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n",
    "- Try to increase the vocabulary size to 256 using a [Byte Pair Encoding](https://arxiv.org/abs/1508.07909) strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why build a language model?\n",
    "\n",
    "Building a language model is not very useful by it-self. However language models have recently been shown to be useful for **transfer learning** to build **contextualized word embeddings** as a better alternative to word2vec or GloVe.\n",
    "\n",
    "Using language-model based word representations makes it possible to reach the **state-of-the-art at many natural language understanding problems**.\n",
    "\n",
    "The workflow is the following:\n",
    "\n",
    "- **train** a (bi-directional) **deep language model on a very large, unlabeled corpus** (e.g. 1 billion words or more);\n",
    "- plug the resulting **language model as the input layer** (and sometimes also the output layer) **of a task specific architecture**, for instance: text classification, semantic role labeling for knowledge extraction, logical entailment, question answering and reading comprehension;\n",
    "- **train the task specific parameters** of the new architecure on the **smaller task-labeled corpus**;\n",
    "- optionally fine-tune the full architecture on the task-labeled corpus if it's big enough not to overfit.\n",
    "\n",
    "More information on this approach:\n",
    "\n",
    "- Deep contextualized word representations, https://arxiv.org/abs/1802.05365\n",
    "- [Pytorch implementation of ELMo](https://github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py) as part of the AllenNLP project: https://github.com/allenai/allennlp\n",
    "- Fine-tuned Language Models for Text Classification https://arxiv.org/abs/1801.06146 (FitLaM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
